---
title: "mSIM"
author: "Zirui Li, Yuan Feng, Luo Xiao, Eric C.Chi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mSIM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mSIM)
```


#package mSIM
## Zirui Li

### Functions

#### get_B_ADMM

##### Usage
get_B_ADMM(Y, X, B = NULL, lambda, rank, alpha=1, control1=list(max.iter=1e2, tol=1e-2), control2=list(ele.sparse=F, row.sparse=T, low.rank=T), select.method='linear', descent.method='bfgs', plot=F)

#####Argument
**Y:**  The index matrix for mSIM in the model fitting process.
**X:**  The covariate matrix for mSIM in the model fitting process.
**B:**  The initial coefficient matrix B. The default value is NULL, and it will be generated by ridge regression. Users can also specify the B matrix.
**lambda:**  The coefficient for regularize term in the optimize process. It should be selected by using **General Cross Validation**.
**rank:**  The rank of final B matrix.
**alpha:**  The step size in the optimize process.
**control1:**  A list that contains the control parameters for the optimize process. It contains 2 arguments: **max.iters** and **tol**. **max.iters** is the max number of iteration and **tol** is the threshold of the error. If the number of iteration is bigger than **max.iter** or the error is less than **tol**, the optimize process will stop.
**control2:**  A list for regularize function. It contains 3 arguments: **ele.sparse**, **row.sparse** and **low.rank**. If **ele.sparse**=T, it will apply a element-wise penalty on the B matrix. If **row.sparse**=T, it will apply a penalty on each row of B matrix. And when **low.sparse**=T, it will apply a rank penalty on the B matrix. The **ele.sparse** and **row.sparse** cannot both be True(T).

**select.method:**  The selection method for link function fitting. The value for this method can be 'linear' and 'nonlinear'. The default value is 'linear'. For more details, please read the paper "Sparse Single Index Models for Multivariate Responses".

**descend.method:**  The optimize algorithm. The package support gradient descend and lbfgs. The value for this argument can be either 'gd', which represent gradient descend, or 'bfgs', which means lbfgs. The default value is 'bfgs'.

**plot:**  A argument that decide whether plot the fitting result. The value should be chosen from T or F. The default value is F.

#####Value
**B.final:**  The output B matrix after the optimize process.
**B.sparse:**  The sparse representation of matrix B.
**B.lowrank:** The low rank representation of matrix B.
**converge:** Whether the optimize process has converged. Value 1 indicts the process is converged.
**iteration:** Number of iterations during the optimization.
**pri.err:**  
**dual.err:**  
**noPenIndex:**  The index of row that is not penalized.

#####Examples
```{R}
X = scale(X)
Y = scale(Y)
result = get_B_ADMM(Y, X, lambda=0.03877, rank=3)
```

#### B_BIC

##### Usage
para_info = B_BIC(Y, X, B, tuning, linear=F)

##### Argument
**Y:**  The index matrix for mSIM in the model fitting process.
**X:**  The covariate matrix for mSIM in the model fitting process.
**B:**  The coefficient matrix B. The matrix B can be represented by its raw representation, sparse representation and low rank representation.
**tuning:**  All combination of tuning parameters.
**linear:**  The default value is F(False).

##### Value
**logMSE:**  The value of log mean square loss.
**BIC.nai**  The value of Bayesian information criterion.
**df.nai:**  The degree of freedom.

##### Examples
```{r}
##Running in parallel

Data = list()
simulation = 1

## generate data
for(simu in 1:simulation){
  set.seed(simu^2 + simu*1000)
  Data[[simu]] = data = data_generate(fun.list, n, p, B.true, snr, cor)
}
range = c(0.25, 0.75)
rank = c(3, 10)
tuning = list() # all combination of tuning parameters
len.tuning = 0
for(i in rank){
  for(j in range){
    len.tuning = len.tuning + 1
    tuning[[len.tuning]] = c(j, i)
  }
} 
ncores = 4 
cl = makeCluster(ncores)
registerDoParallel(cl)
B.simu = foreach(simu=1:simulation, .packages=c('mgcv','Matrix','splines','gtools')) %dopar% {
  data = Data[[simu]]
  Y=data$y.scaled
  X=data$x
  model.admm = list()
  
  # mSIM model
  temp = list()
  for(i in 1:length(tuning)){
    temp[[i]] = get_B_ADMM(Y=Y, X=X, B= NULL, lambda=tuning[[i]][1], rank=tuning[[i]][2], alpha=1, control1=list(max.iter=5e1, tol=1e-3), select.method='linear', plot=F)
  }
  model.admm[[1]] = NULL

  # B for each tuning parameter
  B = list()
  for(i in 1:length(tuning)){
    B[[i]] = temp[[i]]$B.sparse
  }
  model.admm[[2]] = B
  
  # BIC for each tuning parameter
  BIC.msim = NULL
  try(for(i in 1:length(tuning)){
    #print(i)
    BIC.msim = rbind(BIC.msim, B.BIC(Y=Y, X=X, B=B[[i]], tuning=tuning[[i]], linear=F))
  })
  model.admm[[3]] = BIC.msim

  return(model.admm)
}
stopCluster(cl)
```

#### predict

##### Usage
pred <- predict(Y, X, B, Y.true, X.pred)
##### Argument
**Y:**  The index matrix used for fitting.
**X:** The covariate matrix used for fitting.
**B:**  The coefficient matrix.
**Y.true:**  The groundtruth for data that need to be predict.
**X.pred:**  The covariate matrix for prediction.
##### Value
**Y.pred:**  The prediction of X.pred.
**MSE:**   The mean square loss of the predict process.
##### Examples
```{r}

```
